# -*- coding: utf-8 -*-
"""Telecom Churn Analysis with PySpark and Random Forest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FKcI9Lwgh4ZsJfupzjaxH7lzbBgRm8YA
"""

!pip install pyspark
!pip install pandas
!pip install seaborn
!pip install elephas

from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.sql.functions import col, when, mean

spark = SparkSession.builder \
    .appName("Telecom Churn Analysis App") \
    .getOrCreate()

data_path = "telecom_churn.csv"
telecom_df = spark.read.csv(data_path, header=True, inferSchema=True)

telecom_df.show(5)
telecom_df.printSchema()

#removing customerId column
telecom_df=telecom_df.drop("customerID")

#Counting Null values

import matplotlib.pyplot as plt

all_columns = [c for c in telecom_df.columns if c != 'customerID']

for column in all_columns:

    unique_counts = telecom_df.groupBy(column).count().orderBy('count', ascending=False).limit(10)
    unique_counts.show()


    pandas_df = unique_counts.toPandas()
    plt.figure(figsize=(10, 4))
    plt.bar(pandas_df[column], pandas_df['count'], color='skyblue')
    plt.xlabel(column)
    plt.ylabel('Counts')
    plt.title(f'Count of unique values in {column}')
    plt.xticks(rotation=45)
    plt.show()

#Converting Total charges to double
from pyspark.sql.functions import col,when
telecom_df = telecom_df.withColumn("TotalCharges", col("TotalCharges").cast("double"))

unique_counts = telecom_df.groupBy("TotalCharges").count().orderBy('count', ascending=False).limit(10)
unique_counts.show()

from pyspark.sql.functions import when
# Convert "Churn" column to double type
telecom_df = telecom_df.withColumn("Churn", when(col("Churn") == "Yes", 1.0).otherwise(0.0))

#Replacing Null value with mean Values
mean_value = telecom_df.agg(mean(col("TotalCharges"))).collect()[0][0]
telecom_df = telecom_df.na.fill({'TotalCharges': mean_value})
telecom_df.show()

numerical_columns = [item[0] for item in telecom_df.dtypes if item[1] not in ('string', 'timestamp') and item[0] != 'Churn']
numerical_columns

#Detecing outliners in numerical cloumn, calculating mean & SD & Z score has threshold value 3.
from pyspark.sql.functions import mean, stddev, col, abs
for column in numerical_columns:

    stats = telecom_df.select(mean(col(column)).alias('mean'), stddev(col(column)).alias('stddev')).collect()
    mean_val = stats[0]['mean']
    stddev_val = stats[0]['stddev']


    outliers = telecom_df.withColumn('z_score', (col(column) - mean_val) / stddev_val)
    outliers = outliers.filter((abs(col('z_score')) > 3))

    print(f"Outliers in column {column}:")
    outliers.show()

# Calculating co relation matrix, assembling numerical features
from pyspark.ml.stat import Correlation
from pyspark.ml.feature import VectorAssembler
from pyspark.sql.types import IntegerType, FloatType, DoubleType
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


numerical_columns = [field.name for field in telecom_df.schema.fields if isinstance(field.dataType, (IntegerType, FloatType, DoubleType))]

assembler = VectorAssembler(inputCols=numerical_columns, outputCol="features")
feature_vector_df = assembler.transform(telecom_df)

feature_vector_df.show()

correlation_matrix = Correlation.corr(feature_vector_df, "features", method="pearson").head()


correlation_array = correlation_matrix[0].toArray()
correlation_df = pd.DataFrame(correlation_array, index=numerical_columns, columns=numerical_columns)


plt.figure(figsize=(10, 8))
sns.heatmap(correlation_df, annot=True, fmt=".2f", cmap='coolwarm', cbar_kws={'label': 'Correlation coefficient'})
plt.title('Heatmap of Correlation Matrix')
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.show()

from pyspark.sql.functions import col

# Create a new feature for customer engagement level based on usage patterns
telecom_df_prepared = telecom_df.withColumn(
    'EngagementScore',
    (col('tenure') * col('MonthlyCharges')) / col('TotalCharges')
)
telecom_df_prepared = telecom_df_prepared.withColumn(
    'HasInternetService',
    (col('InternetService') != 'No').cast('integer')
)

telecom_df_prepared = telecom_df_prepared.withColumn(
    'TenureTimesMonthlyCharges',
    col('tenure') * col('MonthlyCharges')
)

telecom_df = telecom_df_prepared.withColumn("ServiceScore",
    (when(col("OnlineSecurity") == "Yes", 1).otherwise(0) +
     when(col("OnlineBackup") == "Yes", 1).otherwise(0) +
     when(col("DeviceProtection") == "Yes", 1).otherwise(0)))

'''
coleting all the string datatype columns
'''

categorical_columns = [item[0] for item in telecom_df.dtypes if item[1].startswith('string')]
print(categorical_columns)
print(telecom_df.columns)

# identifying categorical clomuns & creating string indexer
categorical_columns = [item[0] for item in telecom_df.dtypes if item[1].startswith('string')]
indexers = [StringIndexer(inputCol=column, outputCol=column+"_indexed").setHandleInvalid("keep") for column in categorical_columns]

#List of Feature colums
feature_columns = [c+"_indexed" for c in categorical_columns] + [c for c in telecom_df.columns if c not in categorical_columns + ['Churn']]

feature_columns

#Creating a vector assembler
assembler = VectorAssembler(inputCols=feature_columns, outputCol="features")

# Intilazing the random forest classifier
scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")
rf_classifier = RandomForestClassifier(featuresCol="scaledFeatures", labelCol="Churn", numTrees=100)

# #Creating a Pipeline
pipeline = Pipeline(stages=indexers + [assembler, scaler, rf_classifier])

# Spliting the dataset 70 % % 30% , doing fine tuning
(trainingData, testData) = telecom_df.randomSplit([0.7, 0.3], seed=42)


paramGrid = (ParamGridBuilder()
              .addGrid(rf_classifier.maxDepth, [5, 10, 15])
              .addGrid(rf_classifier.numTrees, [50, 100, 150])
              .build())

evaluator = BinaryClassificationEvaluator(labelCol="Churn")

cv = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)

cvModel = cv.fit(trainingData)

best_pipeline_model = cvModel.bestModel

predictions = best_pipeline_model.transform(testData)

roc_auc = evaluator.evaluate(predictions)

print("ROC AUC Score:", roc_auc)

roc_auc

predictions.show()

from pyspark.mllib.evaluation import BinaryClassificationMetrics, MulticlassMetrics

# Selecting  the Churn and prediction columns from the predictions DataFrame
predictionAndTarget = predictions.select("Churn","prediction")

# Calculating  binary classification metrics and multiclass metrics
metrics_binary = BinaryClassificationMetrics(predictionAndTarget.rdd.map(tuple))
metrics_multi = MulticlassMetrics(predictionAndTarget.rdd.map(tuple))


#evaluating the metrics
acc = metrics_multi.accuracy
f1 = metrics_multi.fMeasure(1.0)
precision = metrics_multi.precision(1.0)
recall = metrics_multi.recall(1.0)
auc = metrics_binary.areaUnderROC

print(acc)
print(f1)
print(precision)
print(recall)
print(auc)

!pip install -U scikit-learn scipy matplotlib

# visualizing the Confusion Matrix
pred_labels = predictions.select('prediction').rdd.map(lambda row: row[0]).collect()
true_labels = predictions.select('Churn').rdd.map(lambda row: row[0]).collect()
cm = confusion_matrix(true_labels, pred_labels)
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

#Roc Curve
from sklearn.metrics import roc_curve, auc
probs = predictions.select('Churn', 'probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['Churn'])))
true_labels = probs.map(lambda x: x[1]).collect()
predicted_probs = probs.map(lambda x: x[0]).collect()
fpr, tpr, _ = roc_curve(true_labels, predicted_probs)
roc_auc = auc(fpr, tpr)
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title(' (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

#Checking With Sample data
example_data = [
    (1, "Female", 0, "Yes", "No", 1, "No", "No phone service", "DSL", "No", "Yes", "No", "No", "No", "No", "Month-to-month", "Yes", "Electronic check", 29.85, 29.85),
    (2, "Male", 0, "No", "No", 34, "Yes", "No", "DSL", "Yes", "No", "Yes", "No", "No", "No", "One year", "No", "Mailed check", 56.95, 1889.5),
]


schema = ["customerID", "gender", "SeniorCitizen", "Partner", "Dependents", "tenure", "PhoneService",
          "MultipleLines", "InternetService", "OnlineSecurity", "OnlineBackup", "DeviceProtection",
          "TechSupport", "StreamingTV", "StreamingMovies", "Contract", "PaperlessBilling", "PaymentMethod",
          "MonthlyCharges", "TotalCharges"]

# Create DataFrame from example data and schema
example_df = spark.createDataFrame(example_data, schema)

example_df = example_df.withColumn('EngagementScore', (example_df['tenure'] * example_df['MonthlyCharges']) / example_df['TotalCharges'])
example_df = example_df.withColumn('HasInternetService', (example_df['InternetService'] != 'No').cast('integer'))
example_df = example_df.withColumn('TenureTimesMonthlyCharges', example_df['tenure'] * example_df['MonthlyCharges'])
example_df = example_df.withColumn("ServiceScore",
    (when(example_df["OnlineSecurity"] == "Yes", 1).otherwise(0) +
     when(example_df["OnlineBackup"] == "Yes", 1).otherwise(0) +
     when(example_df["DeviceProtection"] == "Yes", 1).otherwise(0)))

predictionsValidations = best_pipeline_model.transform(example_df)

predictionsValidations.show()

#saving the model
model_path = "pySparkModel"
best_pipeline_model.save(model_path)

# importances = best_pipeline_model.featureImportances

rf_model = best_pipeline_model.stages[-1]  # assuming RF is the last stage in the pipeline

# Get the feature importances
importances = rf_model.featureImportances

# Collecting feature importances
importances_list = [(feature_columns[i], importances[i]) for i in range(len(importances))]
sorted_importances = sorted(importances_list, key=lambda x: x[1], reverse=True)

# Print feature importances
for feature, importance in sorted_importances:
    print(f"Feature: {feature}, Importance: {importance}")